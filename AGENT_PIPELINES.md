# Agent Pipelines Documentation

Ğ­Ñ‚Ğ¾Ñ‚ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ğ¾Ğ¿Ğ¸ÑÑ‹Ğ²Ğ°ĞµÑ‚ Ğ²ÑĞµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ ÑÑ…ĞµĞ¼Ñ‹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ² Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¸ Unsloth, Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ² Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ² Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….

## ĞĞ³Ğ»Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ

1. [Synthetic Data Generation Pipeline](#synthetic-data-generation-pipeline)
2. [AIME Evaluation Pipeline](#aime-evaluation-pipeline)
3. [Training Pipeline (GSM8K/LIMO)](#training-pipeline-gsm8klimo)
4. [Vision OCR Pipeline](#vision-ocr-pipeline)

---

## Synthetic Data Generation Pipeline

### ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ
ĞŸĞ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞ¸Ğ½Ñ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ² (PDF, HTML, YouTube, DOCX, PPT, TXT). Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµÑ‚ QA Ğ¿Ğ°Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ LLM Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞ¾Ğ¹ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ°.

### ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹

**ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ĞºĞ»Ğ°ÑÑ:** `SyntheticDataKit`
**Ğ Ğ°ÑĞ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ:** `unsloth/dataprep/synthetic.py`
**ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ:** `unsloth/dataprep/synthetic_configs.py`

### Ğ¡Ñ…ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SYNTHETIC DATA GENERATION PIPELINE                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ SyntheticDataKit â”‚
   â”‚  .from_pretrainedâ”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€> Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (vLLM server)
            â”‚   - model_name (default: Llama-3.1-8B-Instruct-unsloth-bnb-4bit)
            â”‚   - max_seq_length: 2048
            â”‚   - gpu_memory_utilization: 0.98
            â”‚
            â””â”€> Ğ—Ğ°Ğ¿ÑƒÑĞº vLLM subprocess
                â”œâ”€> ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ ÑĞµÑ€Ğ²ĞµÑ€Ğ° (timeout: 1200s)
                â””â”€> ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ÑÑ‚Ğ°Ñ‚ÑƒÑĞ°: http://localhost:8000/metrics

2. ĞŸĞĞ”Ğ“ĞĞ¢ĞĞ’ĞšĞ
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ prepare_qa_generation  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”œâ”€> Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ¿Ğ°Ğ¿Ğ¾Ğº
            â”‚   - pdf, html, youtube, docx, ppt, txt
            â”‚   - output, generated, cleaned, final
            â”‚
            â””â”€> Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ (synthetic_data_kit_config.yaml)
                - Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°: 0.7
                - top_p: 0.95
                - max_tokens: 512
                - num_pairs: 25
                - cleanup_threshold: 1.0

3. CHUNKING (Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ°)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  chunk_data  â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”œâ”€> Ğ§Ñ‚ĞµĞ½Ğ¸Ğµ Ğ²Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
          â”‚
          â”œâ”€> Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
          â”‚   max_tokens = max_seq_length - max_generation_tokens*2 - 128
          â”‚
          â”œâ”€> Ğ Ğ°ÑÑ‡ĞµÑ‚ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ† chunks Ñ overlap
          â”‚   n_chunks = ceil(length / (max_tokens - overlap))
          â”‚
          â””â”€> Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ chunks Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
              filename_0.txt, filename_1.txt, ...

4. Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ QA ĞŸĞĞ 
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ API Call: /v1/completionsâ”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”œâ”€> ĞŸĞ ĞĞœĞŸĞ¢ 1: Summary Generation (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
          â”‚   â””â”€> Ğ’Ñ…Ğ¾Ğ´: document text
          â”‚   â””â”€> Ğ’Ñ‹Ñ…Ğ¾Ğ´: 3-5 sentence summary
          â”‚
          â””â”€> ĞŸĞ ĞĞœĞŸĞ¢ 2: QA Generation
              â”œâ”€> Ğ’Ñ…Ğ¾Ğ´:
              â”‚   - text: chunked document
              â”‚   - num_pairs: 25
              â”‚   - temperature: 0.7
              â”‚   - top_p: 0.95
              â”‚   - max_tokens: 512
              â”‚
              â””â”€> Ğ’Ñ‹Ñ…Ğ¾Ğ´: JSON array of QA pairs
                  [{"question": "...", "answer": "..."}]

5. ĞĞ¦Ğ•ĞĞšĞ ĞšĞĞ§Ğ•Ğ¡Ğ¢Ğ’Ğ
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ API Call: /v1/completionsâ”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â””â”€> ĞŸĞ ĞĞœĞŸĞ¢ 3: QA Rating
              â”œâ”€> Ğ’Ñ…Ğ¾Ğ´:
              â”‚   - pairs: ÑĞ³ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ QA Ğ¿Ğ°Ñ€Ñ‹
              â”‚   - batch_size: 4
              â”‚   - temperature: 0.3 (Ğ½Ğ¸Ğ¶Ğµ Ğ´Ğ»Ñ ĞºĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸)
              â”‚
              â””â”€> Ğ’Ñ‹Ñ…Ğ¾Ğ´: JSON array with ratings
                  [{"question": "...", "answer": "...", "rating": 8}]

6. Ğ¤Ğ˜Ğ›Ğ¬Ğ¢Ğ ĞĞ¦Ğ˜Ğ¯ Ğ˜ Ğ¡ĞĞ¥Ğ ĞĞĞ•ĞĞ˜Ğ•
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   Cleanup     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€> Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ threshold (1-10 scale)
           â”‚   Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ÑÑ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ğ°Ñ€Ñ‹ Ñ rating >= threshold
           â”‚
           â”œâ”€> Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² cleaned/
           â”‚
           â””â”€> ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ² Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚
               â””â”€> Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ² final/
                   - JSONL format (default)
                   - Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ metadata (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)

7. Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ˜Ğ•
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ cleanup  â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€> ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° vLLM ÑĞµÑ€Ğ²ĞµÑ€Ğ°
        â”‚   - graceful termination (10s timeout)
        â”‚   - force kill if needed
        â”‚
        â”œâ”€> ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° CUDA cache
        â”‚   torch.cuda.empty_cache()
        â”‚
        â””â”€> Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ vLLM Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ
```

### ĞŸĞ¾Ñ‚Ğ¾Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

```
INPUT                    PROCESS                    OUTPUT
â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€

Document.pdf    â”€â”€>  Chunking        â”€â”€>  document_0.txt
                     (overlap=64)          document_1.txt
                                          document_2.txt
                            â”‚
                            â”œâ”€â”€>  QA Generation   â”€â”€>  Raw QA pairs
                            â”‚     (25 pairs/chunk)      (JSON)
                            â”‚
                            â””â”€â”€>  QA Rating       â”€â”€>  Rated QA pairs
                                  (1-10 scale)          (JSON with ratings)
                                       â”‚
                                       â””â”€â”€>  Filtering   â”€â”€>  High-quality QA
                                             (threshold)       (JSONL)
```

### ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸

| ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ | ĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ |
|----------|--------------|----------|
| temperature | 0.7 | ĞšÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ QA |
| top_p | 0.95 | Nucleus sampling |
| chunk_size | max_seq - 2*max_gen - 2 | Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… chunks |
| overlap | 64 | ĞŸĞµÑ€ĞµĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ Ğ¼ĞµĞ¶Ğ´Ñƒ chunks |
| max_tokens | 512 | ĞœĞ°ĞºÑ Ğ´Ğ»Ğ¸Ğ½Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµĞ¼Ğ¾Ğ³Ğ¾ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° |
| num_pairs | 25 | QA Ğ¿Ğ°Ñ€ Ğ½Ğ° chunk |
| cleanup_threshold | 1.0 | ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ |
| cleanup_batch_size | 4 | Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ±Ğ°Ñ‚Ñ‡Ğ° Ğ´Ğ»Ñ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ğ° |
| cleanup_temperature | 0.3 | Ğ¢ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ° Ğ´Ğ»Ñ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³Ğ° |

### API Endpoints

- **Server URL:** `http://localhost:8000/v1`
- **Metrics:** `http://localhost:8000/metrics`
- **Completions:** `http://localhost:8000/v1/completions`

---

## AIME Evaluation Pipeline

### ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ
ĞŸĞ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ´Ğ»Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° ĞºĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ AIME (American Invitational Mathematics Examination). Ğ’ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ test2024, test2025-I Ğ¸ test2025-II. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Pass@k Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ Ñ Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸ĞµĞ¹.

### ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹

**ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ:** `evaluate_model_aime`
**Ğ Ğ°ÑĞ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ:** `tests/utils/aime_eval.py`
**Ğ’ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸:** `load_aime_dataset`, `extract_aime_answer`, `compare_aime_results`

### Ğ¡Ñ…ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AIME EVALUATION PIPELINE                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ Ğ”ĞĞ¢ĞĞ¡Ğ•Ğ¢Ğ
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ download_and_combine_datasets  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€> Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ñ€ĞµÑ… Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ²:
              â”‚   â”œâ”€> test2024.jsonl
              â”‚   â”œâ”€> test2025-I.jsonl
              â”‚   â””â”€> test2025-II.jsonl
              â”‚
              â”œâ”€> ĞšĞ¾Ğ¼Ğ±Ğ¸Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² Ğ¾Ğ´Ğ¸Ğ½ Ñ„Ğ°Ğ¹Ğ»
              â”‚   â””â”€> data/aime/aime.jsonl
              â”‚
              â””â”€> Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:
                  - source_dataset
                  - original_id
                  - global_id

2. Ğ¤ĞĞ ĞœĞĞ¢Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ• ĞŸĞ ĞĞœĞŸĞ¢ĞĞ’
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ load_aime_datasetâ”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â””â”€> Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸:
                {
                  "global_id": N,
                  "source_dataset": "test2024",
                  "problem": "Ñ‚ĞµĞºÑÑ‚ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸",
                  "answer": "123",
                  "prompt": [
                    {
                      "role": "system",
                      "content": "You are a mathematical problem solver..."
                    },
                    {
                      "role": "user",
                      "content": "Problem: ... Solve this step by step..."
                    }
                  ]
                }

3. Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ ĞœĞĞ”Ğ•Ğ›Ğ˜
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ FastLanguageModel.from_  â”‚
   â”‚     pretrained (vLLM)    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€> ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ:
              â”‚   - fast_inference: True (vLLM)
              â”‚   - gpu_memory_utilization: 0.8
              â”‚   - max_seq_length: variable
              â”‚
              â””â”€> Sampling params:
                  - temperature: 0.3
                  - top_p: 0.95
                  - max_tokens: 32768
                  - n: 8 (Ğ¼Ğ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ)
                  - seed: 0

4. Ğ“Ğ•ĞĞ•Ğ ĞĞ¦Ğ˜Ğ¯ Ğ Ğ•Ğ¨Ğ•ĞĞ˜Ğ™ (Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ model.fast_generate     â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”œâ”€> ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ chat template
          â”‚   prompt_text = tokenizer.apply_chat_template(
          â”‚       item["prompt"],
          â”‚       add_generation_prompt=True
          â”‚   )
          â”‚
          â”œâ”€> ĞŸĞ¾Ğ´ÑÑ‡ĞµÑ‚ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²
          â”‚
          â”œâ”€> Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ N=8 Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²
          â”‚   â””â”€> ĞŸĞ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸
          â”‚
          â””â”€> Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²
              outputs = [output.text for output in outputs]

5. Ğ˜Ğ—Ğ’Ğ›Ğ•Ğ§Ğ•ĞĞ˜Ğ• ĞĞ¢Ğ’Ğ•Ğ¢ĞĞ’
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ extract_aime_answer â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”œâ”€> ĞŸĞ¾Ğ¸ÑĞº Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ² (Ğ² Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ°):
          â”‚   1. "the answer is 123"
          â”‚   2. "therefore, the answer is 123"
          â”‚   3. "\boxed{123}"
          â”‚   4. "$\boxed{123}$"
          â”‚   5. "answer: 123"
          â”‚   6. standalone number "123"
          â”‚
          â”œâ”€> Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ (0 <= number <= 999)
          â”‚
          â””â”€> Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ñ‡Ğ¸ÑĞ»Ğ°

6. ĞĞ¦Ğ•ĞĞšĞ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ĞĞ’
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Scoring Logic    â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€> Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸:
        â”‚   â”œâ”€> Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ²ÑĞµÑ… N=8 Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²
        â”‚   â”œâ”€> Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ñ ground truth
        â”‚   â””â”€> is_correct = any(answer == ground_truth)
        â”‚
        â”œâ”€> Ğ Ğ°ÑÑ‡ĞµÑ‚ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº:
        â”‚   â”œâ”€> Accuracy = correct / total * 100
        â”‚   â””â”€> Pass@k = (Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ñ >= 1 Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼) / total * 100
        â”‚
        â””â”€> Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²ĞºĞ° Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°Ğ¼:
            - test2024 accuracy
            - test2025-I accuracy
            - test2025-II accuracy

7. Ğ¡ĞĞ¥Ğ ĞĞĞ•ĞĞ˜Ğ• Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ĞĞ’
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Save to JSON    â”‚
   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â””â”€> Ğ¤Ğ°Ğ¹Ğ»: aime_eval_combined_{model_type}_t{temp}_n{n}.json
            {
              "results": {
                "accuracy": 45.2,
                "pass_at_k": 52.1,
                "source_accuracies": {...},
                "avg_input_tokens": 234,
                "avg_output_tokens": 512
              },
              "records": {
                "0": {
                  "problem": "...",
                  "ground_truth": "123",
                  "responses": [...],
                  "extracted_answers": [...],
                  "is_correct": true,
                  "n_correct": 3,
                  "n_total": 8
                }
              }
            }
```

### ĞŸĞ¾Ñ‚Ğ¾Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

```
Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜Ğš                 ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ              Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢
â”€â”€â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€

GitHub JSONL    â”€â”€>  Download &        â”€â”€>  Combined Dataset
(3 Ñ„Ğ°Ğ¹Ğ»Ğ°)            Combine                 (45+ problems)
                         â”‚
                         â”œâ”€â”€>  Format Prompts    â”€â”€>  Structured Data
                         â”‚     (system + user)
                         â”‚
                         â””â”€â”€>  Generate (N=8)    â”€â”€>  Multiple Solutions
                                    â”‚                  per Problem
                                    â”‚
                                    â”œâ”€â”€>  Extract        â”€â”€>  Numerical Answers
                                    â”‚     Answers             (0-999)
                                    â”‚
                                    â””â”€â”€>  Evaluate       â”€â”€>  Metrics + Records
                                          Pass@k              (JSON)
```

### ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸

**Accuracy:**
```
Accuracy = (ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ >= 1 Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ¼) / Ğ’ÑĞµĞ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ñ‡ * 100
```

**Pass@k:**
```
Pass@k = Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾Ğ³Ğ¾, Ñ‡Ñ‚Ğ¾ Ñ…Ğ¾Ñ‚Ñ Ğ±Ñ‹ Ğ¾Ğ´Ğ¸Ğ½ Ğ¸Ğ· k Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹
       = count(Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ğ³Ğ´Ğµ n_correct > 0) / total_problems * 100
```

**Performance Tiers:**
- ğŸ† EXCEPTIONAL: â‰¥ 50%
- âœ… EXCELLENT: â‰¥ 30%
- ğŸ¯ VERY GOOD: â‰¥ 20%
- âš ï¸ GOOD: â‰¥ 10%
- ğŸ“ˆ FAIR: â‰¥ 5%
- âŒ NEEDS IMPROVEMENT: < 5%

### ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ†ĞµĞ½ĞºĞ¸

| ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ | Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ | ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|----------|----------|------------|
| temperature | 0.3 | ĞĞ¸Ğ·ĞºĞ°Ñ Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² |
| n_sampling | 8 | ĞœĞ½Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Pass@k |
| max_tokens | 32768 | Ğ”Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ Ñ€Ğ°ÑÑÑƒĞ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡ |
| top_p | 0.95 | Nucleus sampling |
| seed | 0 | Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² |

### Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹

**Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ:** `compare_aime_results`

```
INPUT: list of results from multiple models
  â†“
Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ°:
  - Accuracy Ğ¿Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼
  - Pass@K Ğ¿Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑĞ¼
  - Improvement analysis (vs base model)
  - Performance breakdown Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°Ğ¼
  â†“
OUTPUT: aime_model_comparison.json
  - Ğ›ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
  - Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ
```

---

## Training Pipeline (GSM8K/LIMO)

### ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ
ĞŸĞ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° Ğ¼Ğ°Ñ‚ĞµĞ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ°Ñ… GSM8K Ğ¸ LIMO Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ GRPO (Group Relative Policy Optimization). Ğ’ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ LoRA, Ğ¾Ñ†ĞµĞ½ĞºÑƒ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹.

### ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ñ‹

**Ğ Ğ°ÑĞ¿Ğ¾Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ:** `tests/saving/language_models/test_save_merged_grpo_model.py`
**ĞœĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ:** SFT (Supervised Fine-Tuning), GRPO
**Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚Ñ‹:** GSM8K, LIMO

### Ğ¡Ñ…ĞµĞ¼Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRAINING PIPELINE (GSM8K/LIMO)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. Ğ˜ĞĞ˜Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ ĞœĞĞ”Ğ•Ğ›Ğ˜
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ FastLanguageModel.from_      â”‚
   â”‚       pretrained             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”œâ”€> Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° base Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
              â”‚   - model_name: "meta-llama/Llama-3.2-3B-Instruct"
              â”‚   - max_seq_length: 2048
              â”‚   - load_in_4bit: False (Ğ´Ğ»Ñ LoRA 16bit)
              â”‚   - fast_inference: True (vLLM)
              â”‚
              â””â”€> ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ:
                  - max_lora_rank: 64
                  - gpu_memory_utilization: 0.8

2. ĞŸĞĞ”Ğ“ĞĞ¢ĞĞ’ĞšĞ GSM8K Ğ”ĞĞ¢ĞĞ¡Ğ•Ğ¢Ğ
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ prepare_gsm8k_dataset   â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”œâ”€> Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° dataset
          â”‚
          â”œâ”€> ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ system prompt:
          â”‚   "You are given a problem. Think about the problem
          â”‚    and reason step by step. Place your thinking
          â”‚    process between <reasoning> and </reasoning>.
          â”‚    Then, provide your final numerical solution
          â”‚    between <answer></answer>"
          â”‚
          â””â”€> Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ:
              {
                "prompt": [
                  {"role": "system", "content": system_prompt},
                  {"role": "user", "content": question}
                ],
                "answer": extracted_answer  # from "#### 123" format
              }

3. ĞŸĞĞ”Ğ“ĞĞ¢ĞĞ’ĞšĞ LIMO Ğ”ĞĞ¢ĞĞ¡Ğ•Ğ¢Ğ
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ prepare_limo_dataset    â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”œâ”€> Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° dataset
          â”‚
          â”œâ”€> ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ system prompt:
          â”‚   "You are a helpful reasoning assistant.
          â”‚    When given a problem, think through it step by step
          â”‚    and provide your answer in the following format:
          â”‚    <reasoning>...<answer>..."
          â”‚
          â””â”€> Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ SFT:
              {
                "prompt": [
                  {"role": "system", "content": system_prompt},
                  {"role": "user", "content": question},
                  {"role": "assistant", "content": formatted_response}
                ]
              }
              Ğ³Ğ´Ğµ formatted_response =
                "<reasoning>\n{solution}\n</reasoning>\n
                 <answer>\n{answer}\n</answer>"

4. ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ LoRA
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ FastLanguageModel.get_  â”‚
   â”‚      peft_model         â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â””â”€> LoRA Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹:
              - r: 64 (LoRA rank)
              - lora_alpha: 128
              - lora_dropout: 0
              - target_modules: ["q_proj", "k_proj", "v_proj",
                                 "o_proj", "gate_proj", "up_proj",
                                 "down_proj"]
              - bias: "none"
              - use_gradient_checkpointing: True

5. REWARD FUNCTIONS (Ğ´Ğ»Ñ GRPO)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ match_format_exactly     â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”œâ”€> ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ°:
          â”‚   pattern = r"<reasoning>.*</reasoning>.*<answer>.*</answer>"
          â”‚
          â”‚   ĞĞ°Ğ³Ñ€Ğ°Ğ´Ğ°:
          â”‚   - ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚: +1.0
          â”‚   - ĞĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚: -1.0
          â”‚
          â””â”€> ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ÑÑ Ğº ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ completion

6. ĞĞ‘Ğ£Ğ§Ğ•ĞĞ˜Ğ•
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ GRPOTrainer (Ğ¸Ğ»Ğ¸ SFT)   â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”œâ”€> GRPO Training Config:
          â”‚   - learning_rate: 5e-6
          â”‚   - num_train_epochs: 1
          â”‚   - per_device_train_batch_size: 1
          â”‚   - gradient_accumulation_steps: 8
          â”‚   - max_prompt_length: 512
          â”‚   - max_completion_length: 1024
          â”‚   - num_generations: 4
          â”‚
          â”œâ”€> Ğ¦Ğ¸ĞºĞ» Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ:
          â”‚   Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ±Ğ°Ñ‚Ñ‡Ğ°:
          â”‚   â”œâ”€> Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ K=4 completion'Ğ¾Ğ²
          â”‚   â”œâ”€> Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ rewards
          â”‚   â”‚   â””â”€> match_format_exactly(completions)
          â”‚   â”œâ”€> Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ¾ rewards
          â”‚   â””â”€> ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ²ĞµÑĞ¾Ğ² (policy optimization)
          â”‚
          â””â”€> Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ¾Ğ²

7. ĞĞ¦Ğ•ĞĞšĞ ĞœĞĞ”Ğ•Ğ›Ğ˜
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ evaluate_model_aime     â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”œâ”€> Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
          â”‚
          â”œâ”€> Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° AIME Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ
          â”‚   - temperature: 0.3
          â”‚   - n_sampling: 8
          â”‚   - max_tokens: 32768
          â”‚
          â””â”€> Ğ Ğ°ÑÑ‡ĞµÑ‚ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº:
              - Accuracy
              - Pass@k

8. Ğ¡ĞĞ¥Ğ ĞĞĞ•ĞĞ˜Ğ• ĞœĞĞ”Ğ•Ğ›Ğ˜
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ model.save_pretrained   â”‚
   â”‚ (merged)                â”‚
   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”œâ”€> ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ LoRA Ğ²ĞµÑĞ¾Ğ² Ñ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒÑ
          â”‚
          â”œâ”€> Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¾Ğ²:
          â”‚   â”œâ”€> merged_16bit (full precision)
          â”‚   â”œâ”€> merged_4bit (quantized)
          â”‚   â””â”€> lora_adapters (only LoRA weights)
          â”‚
          â””â”€> ĞĞ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ push to HuggingFace Hub
```

### ĞŸĞ¾Ñ‚Ğ¾Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

```
Ğ”ĞĞ¢ĞĞ¡Ğ•Ğ¢              ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ                ĞœĞĞ”Ğ•Ğ›Ğ¬
â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€â”€

GSM8K        â”€â”€>  Format Prompts     â”€â”€>  Training Data
questions         (system + user +        (with <reasoning>
                   extracted answer)        <answer> tags)
                         â”‚
                         â”œâ”€â”€>  LoRA Training    â”€â”€>  Adapted Model
                         â”‚     (GRPO/SFT)            (base + LoRA)
                         â”‚
LIMO         â”€â”€>  Format with        â”€â”€>  Training Data
problems          full solutions          (complete conversations)
                         â”‚
                         â””â”€â”€>  Evaluation       â”€â”€>  Metrics
                               (AIME dataset)        (Accuracy, Pass@k)
                                    â”‚
                                    â””â”€â”€>  Merge & Save   â”€â”€>  Final Model
                                          (16bit/4bit)        (HF format)
```

### Reward Function Logic (GRPO)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   GRPO REWARD CALCULATION                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ completion:

1. CHECK FORMAT
   â”‚
   â”œâ”€> Ğ˜Ñ‰ĞµĞ¼ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½: <reasoning>...<answer>...
   â”‚
   â”œâ”€> Ğ•ÑĞ»Ğ¸ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½:
   â”‚   â””â”€> reward += 1.0
   â”‚
   â””â”€> Ğ•ÑĞ»Ğ¸ ĞĞ• Ğ½Ğ°Ğ¹Ğ´ĞµĞ½:
       â””â”€> reward -= 1.0

2. CHECK CORRECTNESS (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
   â”‚
   â”œâ”€> Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ answer Ğ¸Ğ· <answer>...</answer>
   â”‚
   â”œâ”€> Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ñ‚ÑŒ Ñ ground truth
   â”‚
   â”œâ”€> Ğ•ÑĞ»Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹:
   â”‚   â””â”€> reward += 5.0
   â”‚
   â””â”€> Ğ•ÑĞ»Ğ¸ Ğ½ĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹:
       â””â”€> reward += 0.0

3. GROUP BY REWARDS
   â”‚
   â”œâ”€> Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° completions Ğ¿Ğ¾ rewards
   â”‚
   â””â”€> Ğ Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ³Ñ€ÑƒĞ¿Ğ¿Ñ‹:
       - High reward group (top 50%)
       - Low reward group (bottom 50%)

4. POLICY OPTIMIZATION
   â”‚
   â””â”€> Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡Ğ¸Ñ‚ÑŒ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ high-reward completions
       Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ñ‚ÑŒ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚ÑŒ low-reward completions
```

### ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ

| ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ | SFT | GRPO | ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ |
|----------|-----|------|----------|
| learning_rate | 2e-4 | 5e-6 | GRPO Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğ¹ LR |
| batch_size | 4 | 1 | GRPO Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ¼ĞµĞ½ÑŒÑˆĞ¸Ğ¹ Ğ±Ğ°Ñ‚Ñ‡ |
| gradient_accumulation | 4 | 8 | Ğ”Ğ»Ñ ÑÑ„Ñ„ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ |
| num_generations | - | 4 | ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ completion'Ğ¾Ğ² |
| max_prompt_length | - | 512 | ĞœĞ°ĞºÑ Ğ´Ğ»Ğ¸Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ° |
| max_completion_length | - | 1024 | ĞœĞ°ĞºÑ Ğ´Ğ»Ğ¸Ğ½Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° |
| LoRA rank | 64 | 64 | Ğ Ğ°Ğ·Ğ¼ĞµÑ€ Ğ°Ğ´Ğ°Ğ¿Ñ‚ĞµÑ€Ğ° |

### ĞÑ†ĞµĞ½ĞºĞ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²

ĞŸĞ¾ÑĞ»Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° AIME dataset:

```
Base Model     â”€â”€>  AIME Eval  â”€â”€>  Baseline Accuracy: ~15%

Trained Model  â”€â”€>  AIME Eval  â”€â”€>  Improved Accuracy: ~25%
(GRPO)
                                     Improvement: +10%
```

### Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ

**1. LoRA Adapters Only:**
```
lora_adapters/
â”œâ”€â”€ adapter_config.json
â”œâ”€â”€ adapter_model.safetensors
â””â”€â”€ tokenizer files
```

**2. Merged 16-bit:**
```
merged_16bit/
â”œâ”€â”€ model.safetensors (Ğ¸Ğ»Ğ¸ .bin)
â”œâ”€â”€ config.json
â”œâ”€â”€ tokenizer files
â””â”€â”€ generation_config.json
```

**3. Merged 4-bit:**
```
merged_4bit/
â”œâ”€â”€ model.safetensors (quantized)
â”œâ”€â”€ config.json
â”œâ”€â”€ quantization_config.json
â””â”€â”€ tokenizer files
```

---

