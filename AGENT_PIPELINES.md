# Agent Pipelines Documentation

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ö–µ–º—ã —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–∞ –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ Unsloth, –≤–∫–ª—é—á–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã–∑–æ–≤–æ–≤ –ø—Ä–æ–º–ø—Ç–æ–≤ –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö.

## –û–≥–ª–∞–≤–ª–µ–Ω–∏–µ

1. [Synthetic Data Generation Pipeline](#synthetic-data-generation-pipeline)
2. [AIME Evaluation Pipeline](#aime-evaluation-pipeline)
3. [Training Pipeline (GSM8K/LIMO)](#training-pipeline-gsm8klimo)
4. [Vision OCR Pipeline](#vision-ocr-pipeline)

---

## Synthetic Data Generation Pipeline

### –û–ø–∏—Å–∞–Ω–∏–µ
–ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (PDF, HTML, YouTube, DOCX, PPT, TXT). –°–æ–∑–¥–∞–µ—Ç QA –ø–∞—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è LLM –º–æ–¥–µ–ª–µ–π —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–æ–π –∫–∞—á–µ—Å—Ç–≤–∞.

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

**–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å:** `SyntheticDataKit`
**–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ:** `unsloth/dataprep/synthetic.py`
**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:** `unsloth/dataprep/synthetic_configs.py`

### –°—Ö–µ–º–∞ —Ä–∞–±–æ—Ç—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    SYNTHETIC DATA GENERATION PIPELINE                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ SyntheticDataKit ‚îÇ
   ‚îÇ  .from_pretrained‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚îú‚îÄ> –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (vLLM server)
            ‚îÇ   - model_name (default: Llama-3.1-8B-Instruct-unsloth-bnb-4bit)
            ‚îÇ   - max_seq_length: 2048
            ‚îÇ   - gpu_memory_utilization: 0.98
            ‚îÇ
            ‚îî‚îÄ> –ó–∞–ø—É—Å–∫ vLLM subprocess
                ‚îú‚îÄ> –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞ (timeout: 1200s)
                ‚îî‚îÄ> –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞: http://localhost:8000/metrics

2. –ü–û–î–ì–û–¢–û–í–ö–ê
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ prepare_qa_generation  ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚îú‚îÄ> –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–∞–ø–æ–∫
            ‚îÇ   - pdf, html, youtube, docx, ppt, txt
            ‚îÇ   - output, generated, cleaned, final
            ‚îÇ
            ‚îî‚îÄ> –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (synthetic_data_kit_config.yaml)
                - —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: 0.7
                - top_p: 0.95
                - max_tokens: 512
                - num_pairs: 25
                - cleanup_threshold: 1.0

3. CHUNKING (—Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞)
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ  chunk_data  ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îú‚îÄ> –ß—Ç–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
          ‚îÇ
          ‚îú‚îÄ> –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
          ‚îÇ   max_tokens = max_seq_length - max_generation_tokens*2 - 128
          ‚îÇ
          ‚îú‚îÄ> –†–∞—Å—á–µ—Ç –≥—Ä–∞–Ω–∏—Ü chunks —Å overlap
          ‚îÇ   n_chunks = ceil(length / (max_tokens - overlap))
          ‚îÇ
          ‚îî‚îÄ> –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ chunks –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã
              filename_0.txt, filename_1.txt, ...

4. –ì–ï–ù–ï–†–ê–¶–ò–Ø QA –ü–ê–†
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ API Call: /v1/completions‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îú‚îÄ> –ü–†–û–ú–ü–¢ 1: Summary Generation (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
          ‚îÇ   ‚îî‚îÄ> –í—Ö–æ–¥: document text
          ‚îÇ   ‚îî‚îÄ> –í—ã—Ö–æ–¥: 3-5 sentence summary
          ‚îÇ
          ‚îî‚îÄ> –ü–†–û–ú–ü–¢ 2: QA Generation
              ‚îú‚îÄ> –í—Ö–æ–¥:
              ‚îÇ   - text: chunked document
              ‚îÇ   - num_pairs: 25
              ‚îÇ   - temperature: 0.7
              ‚îÇ   - top_p: 0.95
              ‚îÇ   - max_tokens: 512
              ‚îÇ
              ‚îî‚îÄ> –í—ã—Ö–æ–¥: JSON array of QA pairs
                  [{"question": "...", "answer": "..."}]

5. –û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ API Call: /v1/completions‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îî‚îÄ> –ü–†–û–ú–ü–¢ 3: QA Rating
              ‚îú‚îÄ> –í—Ö–æ–¥:
              ‚îÇ   - pairs: —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ QA –ø–∞—Ä—ã
              ‚îÇ   - batch_size: 4
              ‚îÇ   - temperature: 0.3 (–Ω–∏–∂–µ –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏)
              ‚îÇ
              ‚îî‚îÄ> –í—ã—Ö–æ–¥: JSON array with ratings
                  [{"question": "...", "answer": "...", "rating": 8}]

6. –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ò –°–û–•–†–ê–ù–ï–ù–ò–ï
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ   Cleanup     ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚îú‚îÄ> –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ threshold (1-10 scale)
           ‚îÇ   –°–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–∞—Ä—ã —Å rating >= threshold
           ‚îÇ
           ‚îú‚îÄ> –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ cleaned/
           ‚îÇ
           ‚îî‚îÄ> –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
               ‚îî‚îÄ> –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ final/
                   - JSONL format (default)
                   - –≤–∫–ª—é—á–µ–Ω–∏–µ metadata (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

7. –ó–ê–í–ï–†–®–ï–ù–ò–ï
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ cleanup  ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚îú‚îÄ> –û—Å—Ç–∞–Ω–æ–≤–∫–∞ vLLM —Å–µ—Ä–≤–µ—Ä–∞
        ‚îÇ   - graceful termination (10s timeout)
        ‚îÇ   - force kill if needed
        ‚îÇ
        ‚îú‚îÄ> –û—á–∏—Å—Ç–∫–∞ CUDA cache
        ‚îÇ   torch.cuda.empty_cache()
        ‚îÇ
        ‚îî‚îÄ> –£–¥–∞–ª–µ–Ω–∏–µ vLLM –º–æ–¥—É–ª—è
```

### –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö

```
INPUT                    PROCESS                    OUTPUT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

Document.pdf    ‚îÄ‚îÄ>  Chunking        ‚îÄ‚îÄ>  document_0.txt
                     (overlap=64)          document_1.txt
                                          document_2.txt
                            ‚îÇ
                            ‚îú‚îÄ‚îÄ>  QA Generation   ‚îÄ‚îÄ>  Raw QA pairs
                            ‚îÇ     (25 pairs/chunk)      (JSON)
                            ‚îÇ
                            ‚îî‚îÄ‚îÄ>  QA Rating       ‚îÄ‚îÄ>  Rated QA pairs
                                  (1-10 scale)          (JSON with ratings)
                                       ‚îÇ
                                       ‚îî‚îÄ‚îÄ>  Filtering   ‚îÄ‚îÄ>  High-quality QA
                                             (threshold)       (JSONL)
```

### –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|--------------|----------|
| temperature | 0.7 | –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ QA |
| top_p | 0.95 | Nucleus sampling |
| chunk_size | max_seq - 2*max_gen - 2 | –†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö chunks |
| overlap | 64 | –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É chunks |
| max_tokens | 512 | –ú–∞–∫—Å –¥–ª–∏–Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ |
| num_pairs | 25 | QA –ø–∞—Ä –Ω–∞ chunk |
| cleanup_threshold | 1.0 | –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–µ–π—Ç–∏–Ω–≥ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è |
| cleanup_batch_size | 4 | –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–∞ |
| cleanup_temperature | 0.3 | –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–∞ |

### API Endpoints

- **Server URL:** `http://localhost:8000/v1`
- **Metrics:** `http://localhost:8000/metrics`
- **Completions:** `http://localhost:8000/v1/completions`

---

## AIME Evaluation Pipeline

### –û–ø–∏—Å–∞–Ω–∏–µ
–ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ AIME (American Invitational Mathematics Examination). –í–∫–ª—é—á–∞–µ—Ç test2024, test2025-I –∏ test2025-II. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Pass@k –º–µ—Ç—Ä–∏–∫—É —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π.

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

**–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è:** `evaluate_model_aime`
**–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ:** `tests/utils/aime_eval.py`
**–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:** `load_aime_dataset`, `extract_aime_answer`, `compare_aime_results`

### –°—Ö–µ–º–∞ —Ä–∞–±–æ—Ç—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      AIME EVALUATION PIPELINE                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–¢–ê–°–ï–¢–ê
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ download_and_combine_datasets  ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îú‚îÄ> –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ç—Ä–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤:
              ‚îÇ   ‚îú‚îÄ> test2024.jsonl
              ‚îÇ   ‚îú‚îÄ> test2025-I.jsonl
              ‚îÇ   ‚îî‚îÄ> test2025-II.jsonl
              ‚îÇ
              ‚îú‚îÄ> –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ –æ–¥–∏–Ω —Ñ–∞–π–ª
              ‚îÇ   ‚îî‚îÄ> data/aime/aime.jsonl
              ‚îÇ
              ‚îî‚îÄ> –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö:
                  - source_dataset
                  - original_id
                  - global_id

2. –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –ü–†–û–ú–ü–¢–û–í
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ load_aime_dataset‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚îî‚îÄ> –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏:
                {
                  "global_id": N,
                  "source_dataset": "test2024",
                  "problem": "—Ç–µ–∫—Å—Ç –∑–∞–¥–∞—á–∏",
                  "answer": "123",
                  "prompt": [
                    {
                      "role": "system",
                      "content": "You are a mathematical problem solver..."
                    },
                    {
                      "role": "user",
                      "content": "Problem: ... Solve this step by step..."
                    }
                  ]
                }

3. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ú–û–î–ï–õ–ò
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ FastLanguageModel.from_  ‚îÇ
   ‚îÇ     pretrained (vLLM)    ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îú‚îÄ> –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:
              ‚îÇ   - fast_inference: True (vLLM)
              ‚îÇ   - gpu_memory_utilization: 0.8
              ‚îÇ   - max_seq_length: variable
              ‚îÇ
              ‚îî‚îÄ> Sampling params:
                  - temperature: 0.3
                  - top_p: 0.95
                  - max_tokens: 32768
                  - n: 8 (–º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è)
                  - seed: 0

4. –ì–ï–ù–ï–†–ê–¶–ò–Ø –†–ï–®–ï–ù–ò–ô (–¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏)
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ model.fast_generate     ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îú‚îÄ> –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ chat template
          ‚îÇ   prompt_text = tokenizer.apply_chat_template(
          ‚îÇ       item["prompt"],
          ‚îÇ       add_generation_prompt=True
          ‚îÇ   )
          ‚îÇ
          ‚îú‚îÄ> –ü–æ–¥—Å—á–µ—Ç –≤—Ö–æ–¥–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
          ‚îÇ
          ‚îú‚îÄ> –ì–µ–Ω–µ—Ä–∞—Ü–∏—è N=8 –æ—Ç–≤–µ—Ç–æ–≤
          ‚îÇ   ‚îî‚îÄ> –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
          ‚îÇ
          ‚îî‚îÄ> –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤
              outputs = [output.text for output in outputs]

5. –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –û–¢–í–ï–¢–û–í
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ extract_aime_answer ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îú‚îÄ> –ü–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ (–≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞):
          ‚îÇ   1. "the answer is 123"
          ‚îÇ   2. "therefore, the answer is 123"
          ‚îÇ   3. "\boxed{123}"
          ‚îÇ   4. "$\boxed{123}$"
          ‚îÇ   5. "answer: 123"
          ‚îÇ   6. standalone number "123"
          ‚îÇ
          ‚îú‚îÄ> –í–∞–ª–∏–¥–∞—Ü–∏—è (0 <= number <= 999)
          ‚îÇ
          ‚îî‚îÄ> –í–æ–∑–≤—Ä–∞—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —á–∏—Å–ª–∞

6. –û–¶–ï–ù–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Scoring Logic    ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚îú‚îÄ> –î–ª—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏:
        ‚îÇ   ‚îú‚îÄ> –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö N=8 –æ—Ç–≤–µ—Ç–æ–≤
        ‚îÇ   ‚îú‚îÄ> –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å ground truth
        ‚îÇ   ‚îî‚îÄ> is_correct = any(answer == ground_truth)
        ‚îÇ
        ‚îú‚îÄ> –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫:
        ‚îÇ   ‚îú‚îÄ> Accuracy = correct / total * 100
        ‚îÇ   ‚îî‚îÄ> Pass@k = (–∑–∞–¥–∞—á–∏ —Å >= 1 –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º) / total * 100
        ‚îÇ
        ‚îî‚îÄ> –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –¥–∞—Ç–∞—Å–µ—Ç–∞–º:
            - test2024 accuracy
            - test2025-I accuracy
            - test2025-II accuracy

7. –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Save to JSON    ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚îî‚îÄ> –§–∞–π–ª: aime_eval_combined_{model_type}_t{temp}_n{n}.json
            {
              "results": {
                "accuracy": 45.2,
                "pass_at_k": 52.1,
                "source_accuracies": {...},
                "avg_input_tokens": 234,
                "avg_output_tokens": 512
              },
              "records": {
                "0": {
                  "problem": "...",
                  "ground_truth": "123",
                  "responses": [...],
                  "extracted_answers": [...],
                  "is_correct": true,
                  "n_correct": 3,
                  "n_total": 8
                }
              }
            }
```

### –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö

```
–ò–°–¢–û–ß–ù–ò–ö                 –û–ë–†–ê–ë–û–¢–ö–ê              –†–ï–ó–£–õ–¨–¢–ê–¢
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ              ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

GitHub JSONL    ‚îÄ‚îÄ>  Download &        ‚îÄ‚îÄ>  Combined Dataset
(3 —Ñ–∞–π–ª–∞)            Combine                 (45+ problems)
                         ‚îÇ
                         ‚îú‚îÄ‚îÄ>  Format Prompts    ‚îÄ‚îÄ>  Structured Data
                         ‚îÇ     (system + user)
                         ‚îÇ
                         ‚îî‚îÄ‚îÄ>  Generate (N=8)    ‚îÄ‚îÄ>  Multiple Solutions
                                    ‚îÇ                  per Problem
                                    ‚îÇ
                                    ‚îú‚îÄ‚îÄ>  Extract        ‚îÄ‚îÄ>  Numerical Answers
                                    ‚îÇ     Answers             (0-999)
                                    ‚îÇ
                                    ‚îî‚îÄ‚îÄ>  Evaluate       ‚îÄ‚îÄ>  Metrics + Records
                                          Pass@k              (JSON)
```

### –ú–µ—Ç—Ä–∏–∫–∏

**Accuracy:**
```
Accuracy = (–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á —Å >= 1 –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º) / –í—Å–µ–≥–æ –∑–∞–¥–∞—á * 100
```

**Pass@k:**
```
Pass@k = –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–≥–æ, —á—Ç–æ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∏–∑ k –æ—Ç–≤–µ—Ç–æ–≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
       = count(–∑–∞–¥–∞—á–∏ –≥–¥–µ n_correct > 0) / total_problems * 100
```

**Performance Tiers:**
- üèÜ EXCEPTIONAL: ‚â• 50%
- ‚úÖ EXCELLENT: ‚â• 30%
- üéØ VERY GOOD: ‚â• 20%
- ‚ö†Ô∏è GOOD: ‚â• 10%
- üìà FAIR: ‚â• 5%
- ‚ùå NEEDS IMPROVEMENT: < 5%

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|----------|----------|------------|
| temperature | 0.3 | –ù–∏–∑–∫–∞—è –¥–ª—è —Ç–æ—á–Ω—ã—Ö –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ |
| n_sampling | 8 | –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–ª—è Pass@k |
| max_tokens | 32768 | –î–ª–∏–Ω–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á |
| top_p | 0.95 | Nucleus sampling |
| seed | 0 | –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ |

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

**–§—É–Ω–∫—Ü–∏—è:** `compare_aime_results`

```
INPUT: list of results from multiple models
  ‚Üì
–°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞:
  - Accuracy –ø–æ –º–æ–¥–µ–ª—è–º
  - Pass@K –ø–æ –º–æ–¥–µ–ª—è–º
  - Improvement analysis (vs base model)
  - Performance breakdown –ø–æ –¥–∞—Ç–∞—Å–µ—Ç–∞–º
  ‚Üì
OUTPUT: aime_model_comparison.json
  - –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å
  - –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
```

---

## Training Pipeline (GSM8K/LIMO)

### –û–ø–∏—Å–∞–Ω–∏–µ
–ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö GSM8K –∏ LIMO —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GRPO (Group Relative Policy Optimization). –í–∫–ª—é—á–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö, –æ–±—É—á–µ–Ω–∏–µ —Å LoRA, –æ—Ü–µ–Ω–∫—É –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π.

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

**–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ:** `tests/saving/language_models/test_save_merged_grpo_model.py`
**–ú–µ—Ç–æ–¥—ã –æ–±—É—á–µ–Ω–∏—è:** SFT (Supervised Fine-Tuning), GRPO
**–î–∞—Ç–∞—Å–µ—Ç—ã:** GSM8K, LIMO

### –°—Ö–µ–º–∞ —Ä–∞–±–æ—Ç—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    TRAINING PIPELINE (GSM8K/LIMO)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ú–û–î–ï–õ–ò
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ FastLanguageModel.from_      ‚îÇ
   ‚îÇ       pretrained             ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îú‚îÄ> –ó–∞–≥—Ä—É–∑–∫–∞ base –º–æ–¥–µ–ª–∏
              ‚îÇ   - model_name: "meta-llama/Llama-3.2-3B-Instruct"
              ‚îÇ   - max_seq_length: 2048
              ‚îÇ   - load_in_4bit: False (–¥–ª—è LoRA 16bit)
              ‚îÇ   - fast_inference: True (vLLM)
              ‚îÇ
              ‚îî‚îÄ> –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:
                  - max_lora_rank: 64
                  - gpu_memory_utilization: 0.8

2. –ü–û–î–ì–û–¢–û–í–ö–ê GSM8K –î–ê–¢–ê–°–ï–¢–ê
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ prepare_gsm8k_dataset   ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îú‚îÄ> –ó–∞–≥—Ä—É–∑–∫–∞ dataset
          ‚îÇ
          ‚îú‚îÄ> –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ system prompt:
          ‚îÇ   "You are given a problem. Think about the problem
          ‚îÇ    and reason step by step. Place your thinking
          ‚îÇ    process between <reasoning> and </reasoning>.
          ‚îÇ    Then, provide your final numerical solution
          ‚îÇ    between <answer></answer>"
          ‚îÇ
          ‚îî‚îÄ> –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:
              {
                "prompt": [
                  {"role": "system", "content": system_prompt},
                  {"role": "user", "content": question}
                ],
                "answer": extracted_answer  # from "#### 123" format
              }

3. –ü–û–î–ì–û–¢–û–í–ö–ê LIMO –î–ê–¢–ê–°–ï–¢–ê
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ prepare_limo_dataset    ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îú‚îÄ> –ó–∞–≥—Ä—É–∑–∫–∞ dataset
          ‚îÇ
          ‚îú‚îÄ> –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ system prompt:
          ‚îÇ   "You are a helpful reasoning assistant.
          ‚îÇ    When given a problem, think through it step by step
          ‚îÇ    and provide your answer in the following format:
          ‚îÇ    <reasoning>...<answer>..."
          ‚îÇ
          ‚îî‚îÄ> –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è SFT:
              {
                "prompt": [
                  {"role": "system", "content": system_prompt},
                  {"role": "user", "content": question},
                  {"role": "assistant", "content": formatted_response}
                ]
              }
              –≥–¥–µ formatted_response =
                "<reasoning>\n{solution}\n</reasoning>\n
                 <answer>\n{answer}\n</answer>"

4. –ù–ê–°–¢–†–û–ô–ö–ê LoRA
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ FastLanguageModel.get_  ‚îÇ
   ‚îÇ      peft_model         ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îî‚îÄ> LoRA –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
              - r: 64 (LoRA rank)
              - lora_alpha: 128
              - lora_dropout: 0
              - target_modules: ["q_proj", "k_proj", "v_proj",
                                 "o_proj", "gate_proj", "up_proj",
                                 "down_proj"]
              - bias: "none"
              - use_gradient_checkpointing: True

5. REWARD FUNCTIONS (–¥–ª—è GRPO)
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ match_format_exactly     ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îú‚îÄ> –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞:
          ‚îÇ   pattern = r"<reasoning>.*</reasoning>.*<answer>.*</answer>"
          ‚îÇ
          ‚îÇ   –ù–∞–≥—Ä–∞–¥–∞:
          ‚îÇ   - –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: +1.0
          ‚îÇ   - –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: -1.0
          ‚îÇ
          ‚îî‚îÄ> –ü—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫ –∫–∞–∂–¥–æ–º—É completion

6. –û–ë–£–ß–ï–ù–ò–ï
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ GRPOTrainer (–∏–ª–∏ SFT)   ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îú‚îÄ> GRPO Training Config:
          ‚îÇ   - learning_rate: 5e-6
          ‚îÇ   - num_train_epochs: 1
          ‚îÇ   - per_device_train_batch_size: 1
          ‚îÇ   - gradient_accumulation_steps: 8
          ‚îÇ   - max_prompt_length: 512
          ‚îÇ   - max_completion_length: 1024
          ‚îÇ   - num_generations: 4
          ‚îÇ
          ‚îú‚îÄ> –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è:
          ‚îÇ   –î–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞:
          ‚îÇ   ‚îú‚îÄ> –ì–µ–Ω–µ—Ä–∞—Ü–∏—è K=4 completion'–æ–≤
          ‚îÇ   ‚îú‚îÄ> –í—ã—á–∏—Å–ª–µ–Ω–∏–µ rewards
          ‚îÇ   ‚îÇ   ‚îî‚îÄ> match_format_exactly(completions)
          ‚îÇ   ‚îú‚îÄ> –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ rewards
          ‚îÇ   ‚îî‚îÄ> –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ (policy optimization)
          ‚îÇ
          ‚îî‚îÄ> –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤

7. –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ evaluate_model_aime     ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îú‚îÄ> –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
          ‚îÇ
          ‚îú‚îÄ> –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–∞ AIME –¥–∞—Ç–∞—Å–µ—Ç–µ
          ‚îÇ   - temperature: 0.3
          ‚îÇ   - n_sampling: 8
          ‚îÇ   - max_tokens: 32768
          ‚îÇ
          ‚îî‚îÄ> –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫:
              - Accuracy
              - Pass@k

8. –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ model.save_pretrained   ‚îÇ
   ‚îÇ (merged)                ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚îú‚îÄ> –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ LoRA –≤–µ—Å–æ–≤ —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
          ‚îÇ
          ‚îú‚îÄ> –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–æ–≤:
          ‚îÇ   ‚îú‚îÄ> merged_16bit (full precision)
          ‚îÇ   ‚îú‚îÄ> merged_4bit (quantized)
          ‚îÇ   ‚îî‚îÄ> lora_adapters (only LoRA weights)
          ‚îÇ
          ‚îî‚îÄ> –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π push to HuggingFace Hub
```

### –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö

```
–î–ê–¢–ê–°–ï–¢              –û–ë–†–ê–ë–û–¢–ö–ê                –ú–û–î–ï–õ–¨
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ              ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

GSM8K        ‚îÄ‚îÄ>  Format Prompts     ‚îÄ‚îÄ>  Training Data
questions         (system + user +        (with <reasoning>
                   extracted answer)        <answer> tags)
                         ‚îÇ
                         ‚îú‚îÄ‚îÄ>  LoRA Training    ‚îÄ‚îÄ>  Adapted Model
                         ‚îÇ     (GRPO/SFT)            (base + LoRA)
                         ‚îÇ
LIMO         ‚îÄ‚îÄ>  Format with        ‚îÄ‚îÄ>  Training Data
problems          full solutions          (complete conversations)
                         ‚îÇ
                         ‚îî‚îÄ‚îÄ>  Evaluation       ‚îÄ‚îÄ>  Metrics
                               (AIME dataset)        (Accuracy, Pass@k)
                                    ‚îÇ
                                    ‚îî‚îÄ‚îÄ>  Merge & Save   ‚îÄ‚îÄ>  Final Model
                                          (16bit/4bit)        (HF format)
```

### Reward Function Logic (GRPO)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   GRPO REWARD CALCULATION                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

–î–ª—è –∫–∞–∂–¥–æ–≥–æ completion:

1. CHECK FORMAT
   ‚îÇ
   ‚îú‚îÄ> –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω: <reasoning>...<answer>...
   ‚îÇ
   ‚îú‚îÄ> –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω:
   ‚îÇ   ‚îî‚îÄ> reward += 1.0
   ‚îÇ
   ‚îî‚îÄ> –ï—Å–ª–∏ –ù–ï –Ω–∞–π–¥–µ–Ω:
       ‚îî‚îÄ> reward -= 1.0

2. CHECK CORRECTNESS (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
   ‚îÇ
   ‚îú‚îÄ> –ò–∑–≤–ª–µ—á—å answer –∏–∑ <answer>...</answer>
   ‚îÇ
   ‚îú‚îÄ> –°—Ä–∞–≤–Ω–∏—Ç—å —Å ground truth
   ‚îÇ
   ‚îú‚îÄ> –ï—Å–ª–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π:
   ‚îÇ   ‚îî‚îÄ> reward += 5.0
   ‚îÇ
   ‚îî‚îÄ> –ï—Å–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π:
       ‚îî‚îÄ> reward += 0.0

3. GROUP BY REWARDS
   ‚îÇ
   ‚îú‚îÄ> –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ completions –ø–æ rewards
   ‚îÇ
   ‚îî‚îÄ> –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –≥—Ä—É–ø–ø—ã:
       - High reward group (top 50%)
       - Low reward group (bottom 50%)

4. POLICY OPTIMIZATION
   ‚îÇ
   ‚îî‚îÄ> –£–≤–µ–ª–∏—á–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å high-reward completions
       –£–º–µ–Ω—å—à–∏—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å low-reward completions
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è

| –ü–∞—Ä–∞–º–µ—Ç—Ä | SFT | GRPO | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|-----|------|----------|
| learning_rate | 2e-4 | 5e-6 | GRPO —Ç—Ä–µ–±—É–µ—Ç –º–µ–Ω—å—à–∏–π LR |
| batch_size | 4 | 1 | GRPO –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ–Ω—å—à–∏–π –±–∞—Ç—á |
| gradient_accumulation | 4 | 8 | –î–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏ |
| num_generations | - | 4 | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ completion'–æ–≤ |
| max_prompt_length | - | 512 | –ú–∞–∫—Å –¥–ª–∏–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞ |
| max_completion_length | - | 1024 | –ú–∞–∫—Å –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ |
| LoRA rank | 64 | 64 | –†–∞–∑–º–µ—Ä –∞–¥–∞–ø—Ç–µ—Ä–∞ |

### –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª—å –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è –Ω–∞ AIME dataset:

```
Base Model     ‚îÄ‚îÄ>  AIME Eval  ‚îÄ‚îÄ>  Baseline Accuracy: ~15%

Trained Model  ‚îÄ‚îÄ>  AIME Eval  ‚îÄ‚îÄ>  Improved Accuracy: ~25%
(GRPO)
                                     Improvement: +10%
```

### –§–æ—Ä–º–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

**1. LoRA Adapters Only:**
```
lora_adapters/
‚îú‚îÄ‚îÄ adapter_config.json
‚îú‚îÄ‚îÄ adapter_model.safetensors
‚îî‚îÄ‚îÄ tokenizer files
```

**2. Merged 16-bit:**
```
merged_16bit/
‚îú‚îÄ‚îÄ model.safetensors (–∏–ª–∏ .bin)
‚îú‚îÄ‚îÄ config.json
‚îú‚îÄ‚îÄ tokenizer files
‚îî‚îÄ‚îÄ generation_config.json
```

**3. Merged 4-bit:**
```
merged_4bit/
‚îú‚îÄ‚îÄ model.safetensors (quantized)
‚îú‚îÄ‚îÄ config.json
‚îú‚îÄ‚îÄ quantization_config.json
‚îî‚îÄ‚îÄ tokenizer files
```

---

## Vision OCR Pipeline

### –û–ø–∏—Å–∞–Ω–∏–µ
–ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏ Vision –º–æ–¥–µ–ª–µ–π –Ω–∞ –∑–∞–¥–∞—á–∞—Ö OCR (Optical Character Recognition). –í–∫–ª—é—á–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ OCR —Å –æ—Ü–µ–Ω–∫–æ–π –∫–∞—á–µ—Å—Ç–≤–∞ —á–µ—Ä–µ–∑ WER –∏ CER –º–µ—Ç—Ä–∏–∫–∏.

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

**–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å:** `OCRModelEvaluator`
**–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ:**
- –û–±—É—á–µ–Ω–∏–µ: `tests/saving/vision_models/test_save_merge_vision_model_ocr_benchmark.py`
- –û—Ü–µ–Ω–∫–∞: `tests/utils/ocr_eval.py`
**–ú–æ–¥–µ–ª—å:** Qwen2-VL-7B-Instruct

### –°—Ö–µ–º–∞ —Ä–∞–±–æ—Ç—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        VISION OCR PIPELINE                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–¢–ê–°–ï–¢–ê
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ load_dataset (HuggingFace)       ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îú‚îÄ> Dataset: "lbourdois/OCR-liboaccn-OPUS-MIT-5M-clean"
              ‚îÇ   Language: "en"
              ‚îÇ
              ‚îú‚îÄ> Training split:
              ‚îÇ   ‚îî‚îÄ> range(2000) - –ø–µ—Ä–≤—ã–µ 2000 –ø—Ä–∏–º–µ—Ä–æ–≤
              ‚îÇ
              ‚îî‚îÄ> Evaluation split:
                  ‚îî‚îÄ> range(2000, 2200) - —Å–ª–µ–¥—É—é—â–∏–µ 200 –ø—Ä–∏–º–µ—Ä–æ–≤

2. –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –î–ê–ù–ù–´–•
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ format_data      ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
            ‚îÇ
            ‚îî‚îÄ> –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞:
                {
                  "messages": [
                    {
                      "role": "system",
                      "content": [
                        {"type": "text", "text": "You are an expert french ocr system."}
                      ]
                    },
                    {
                      "role": "user",
                      "content": [
                        {"type": "text", "text": question},
                        {"type": "image", "image": PIL_Image}
                      ]
                    },
                    {
                      "role": "assistant",
                      "content": [
                        {"type": "text", "text": answer}
                      ]
                    }
                  ]
                }

3. –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø BASE MODEL
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ FastVisionModel.from_        ‚îÇ
   ‚îÇ      pretrained              ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îú‚îÄ> –ú–æ–¥–µ–ª—å: "unsloth/Qwen2-VL-7B-Instruct"
              ‚îÇ   - max_seq_length: 2048
              ‚îÇ   - load_in_4bit: True
              ‚îÇ   - full_finetuning: False (–∏—Å–ø–æ–ª—å–∑—É–µ–º LoRA)
              ‚îÇ
              ‚îî‚îÄ> Base model evaluation:
                  ‚îú‚îÄ> FastVisionModel.for_inference(model)
                  ‚îú‚îÄ> OCR evaluation –Ω–∞ eval_dataset
                  ‚îî‚îÄ> –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ baseline –º–µ—Ç—Ä–∏–∫ (WER, CER)

4. –ù–ê–°–¢–†–û–ô–ö–ê LoRA –î–õ–Ø VISION
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ FastVisionModel.get_peft_    ‚îÇ
   ‚îÇ          model               ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îî‚îÄ> Vision LoRA –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:
                  - finetune_vision_layers: True
                  - finetune_language_layers: True
                  - finetune_attention_modules: True
                  - finetune_mlp_modules: True
                  - r: 16 (LoRA rank –¥–ª—è vision)
                  - lora_alpha: 32
                  - lora_dropout: 0
                  - bias: "none"
                  - use_gradient_checkpointing: "unsloth"

5. –û–ë–£–ß–ï–ù–ò–ï
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ SFTTrainer (Vision)          ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îú‚îÄ> Training Config:
              ‚îÇ   - per_device_train_batch_size: 2
              ‚îÇ   - gradient_accumulation_steps: 4
              ‚îÇ   - max_steps: 60 (–∏–ª–∏ num_train_epochs: 2)
              ‚îÇ   - learning_rate: 2e-4
              ‚îÇ   - max_grad_norm: 0.3
              ‚îÇ   - warmup_ratio: 0.03
              ‚îÇ   - optim: "adamw_torch_fused"
              ‚îÇ
              ‚îú‚îÄ> Data Collator:
              ‚îÇ   ‚îî‚îÄ> UnslothVisionDataCollator(model, tokenizer)
              ‚îÇ       - –û–±—Ä–∞–±–æ—Ç–∫–∞ vision_info (images)
              ‚îÇ       - –°–æ–∑–¥–∞–Ω–∏–µ attention masks
              ‚îÇ       - Padding sequences
              ‚îÇ
              ‚îî‚îÄ> Training Loop:
                  –î–ª—è –∫–∞–∂–¥–æ–≥–æ –±–∞—Ç—á–∞:
                  ‚îú‚îÄ> Process vision info (images)
                  ‚îú‚îÄ> Apply chat template
                  ‚îú‚îÄ> Forward pass (vision + language)
                  ‚îú‚îÄ> Compute loss
                  ‚îî‚îÄ> Backward pass + optimizer step

6. –û–¶–ï–ù–ö–ê –ü–û–°–õ–ï –û–ë–£–ß–ï–ù–ò–Ø
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ OCRModelEvaluator.evaluate_  ‚îÇ
   ‚îÇ          model               ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îú‚îÄ> –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –≤ eval_dataset:
              ‚îÇ   ‚îÇ
              ‚îÇ   ‚îú‚îÄ> –ì–ï–ù–ï–†–ê–¶–ò–Ø:
              ‚îÇ   ‚îÇ   ‚îú‚îÄ> Apply chat template
              ‚îÇ   ‚îÇ   ‚îú‚îÄ> Process vision info
              ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ> process_vision_info(messages)
              ‚îÇ   ‚îÇ   ‚îÇ       - –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ images/videos
              ‚îÇ   ‚îÇ   ‚îÇ       - –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –º–æ–¥–µ–ª–∏
              ‚îÇ   ‚îÇ   ‚îú‚îÄ> Create inputs:
              ‚îÇ   ‚îÇ   ‚îÇ   processor(text, images, videos)
              ‚îÇ   ‚îÇ   ‚îî‚îÄ> Generate:
              ‚îÇ   ‚îÇ       - max_new_tokens: 1024
              ‚îÇ   ‚îÇ       - temperature: 1.5
              ‚îÇ   ‚îÇ       - min_p: 0.1
              ‚îÇ   ‚îÇ
              ‚îÇ   ‚îú‚îÄ> –†–ê–°–ß–ï–¢ –ú–ï–¢–†–ò–ö:
              ‚îÇ   ‚îÇ   ‚îú‚îÄ> WER (Word Error Rate):
              ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ> wer(ground_truth, generated)
              ‚îÇ   ‚îÇ   ‚îî‚îÄ> CER (Character Error Rate):
              ‚îÇ   ‚îÇ       ‚îî‚îÄ> cer(ground_truth, generated)
              ‚îÇ   ‚îÇ
              ‚îÇ   ‚îî‚îÄ> –°–û–•–†–ê–ù–ï–ù–ò–ï:
              ‚îÇ       ‚îú‚îÄ> Individual result (sample_N.txt)
              ‚îÇ       ‚îî‚îÄ> Record for summary
              ‚îÇ
              ‚îî‚îÄ> SUMMARY:
                  ‚îú‚îÄ> Average WER
                  ‚îú‚îÄ> Average CER
                  ‚îú‚îÄ> Detailed results CSV
                  ‚îî‚îÄ> Metrics file

7. –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ OCRModelEvaluator.print_     ‚îÇ
   ‚îÇ    model_comparison          ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îú‚îÄ> –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞:
              ‚îÇ   Model          WER      CER
              ‚îÇ   ------------------------------------
              ‚îÇ   Base Model     0.245    0.123
              ‚îÇ   LoRA Model     0.187    0.089
              ‚îÇ   Merged 16bit   0.185    0.088
              ‚îÇ   Merged 4bit    0.189    0.091
              ‚îÇ
              ‚îî‚îÄ> –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:
                  ‚îú‚îÄ> Bar charts (WER & CER)
                  ‚îî‚îÄ> –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ: ocr_model_comparison.png

8. –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ model.save_pretrained_merged ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚îú‚îÄ> –§–æ—Ä–º–∞—Ç—ã:
              ‚îÇ   ‚îú‚îÄ> merged_16bit/ (Vision + Language)
              ‚îÇ   ‚îú‚îÄ> merged_4bit/ (quantized)
              ‚îÇ   ‚îî‚îÄ> gguf/ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
              ‚îÇ
              ‚îî‚îÄ> Push to Hub (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ):
                  model.push_to_hub_merged(
                      "username/model-name",
                      save_method="merged_16bit"
                  )
```

### –ü–æ—Ç–æ–∫ –¥–∞–Ω–Ω—ã—Ö

```
–í–•–û–î                     –û–ë–†–ê–ë–û–¢–ö–ê                  –í–´–•–û–î
‚îÄ‚îÄ‚îÄ‚îÄ                     ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

Image (PIL)     ‚îÄ‚îÄ>  Vision Encoder        ‚îÄ‚îÄ>  Image Features
+ Question           (Qwen2-VL)                 (embeddings)
                            ‚îÇ
                            ‚îú‚îÄ>  Vision-Language   ‚îÄ‚îÄ>  Contextual
                            ‚îÇ    Fusion                 Features
                            ‚îÇ    (attention)
                            ‚îÇ
Text Tokens     ‚îÄ‚îÄ>  Language Model        ‚îÄ‚îÄ>  Text Features
(question)           (Qwen2)                    (embeddings)
                            ‚îÇ
                            ‚îî‚îÄ>  Generation        ‚îÄ‚îÄ>  OCR Output
                                 (autoregressive)       (text)
                                       ‚îÇ
                                       ‚îî‚îÄ>  Metrics       ‚îÄ‚îÄ>  WER, CER
                                            (jiwer)
```

### –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏

**1. WER (Word Error Rate):**
```
WER = (Substitutions + Insertions + Deletions) / Total Words in Reference

–ü—Ä–∏–º–µ—Ä:
Reference:  "Le chat est noir"
Generated:  "Le chien est noire"

WER = (1 substitution + 0 insertions + 0 deletions + 1 substitution) / 4
    = 2 / 4 = 0.5 (50%)
```

**2. CER (Character Error Rate):**
```
CER = (Substitutions + Insertions + Deletions) / Total Characters in Reference

–ü—Ä–∏–º–µ—Ä:
Reference:  "Le chat"
Generated:  "Le chien"

CER = (edit distance) / len(reference)
```

**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:**
- **Excellent**: WER < 0.05, CER < 0.02
- **Good**: WER < 0.10, CER < 0.05
- **Fair**: WER < 0.20, CER < 0.10
- **Poor**: WER > 0.20, CER > 0.10

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Vision Training

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|----------|----------|
| model | Qwen2-VL-7B-Instruct | Base vision-language model |
| max_seq_length | 2048 | –ú–∞–∫—Å –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ |
| batch_size | 2 | –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ (vision —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏) |
| gradient_accumulation | 4 | –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch_size = 2*4 = 8 |
| learning_rate | 2e-4 | –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –¥–ª—è LoRA |
| max_steps | 60 | –ò–ª–∏ num_train_epochs: 2 |
| LoRA rank (r) | 16 | –ú–µ–Ω—å—à–µ —á–µ–º –¥–ª—è language-only |
| lora_alpha | 32 | ratio = alpha/r = 2.0 |
| temperature (inference) | 1.5 | –í—ã—à–µ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è OCR |
| min_p (inference) | 0.1 | Minimum probability threshold |

### Data Collator –¥–ª—è Vision

```python
UnslothVisionDataCollator –ø—Ä–æ—Ü–µ—Å—Å:

1. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞:
   ‚îÇ
   ‚îú‚îÄ> –ü—Ä–∏–º–µ–Ω–∏—Ç—å chat template
   ‚îÇ   text = processor.apply_chat_template(
   ‚îÇ       messages, add_generation_prompt=True
   ‚îÇ   )
   ‚îÇ
   ‚îú‚îÄ> –û–±—Ä–∞–±–æ—Ç–∞—Ç—å vision info
   ‚îÇ   image_inputs, video_inputs = process_vision_info(messages)
   ‚îÇ
   ‚îú‚îÄ> –°–æ–∑–¥–∞—Ç—å inputs
   ‚îÇ   inputs = processor(
   ‚îÇ       text=[text],
   ‚îÇ       images=image_inputs,
   ‚îÇ       videos=video_inputs,
   ‚îÇ       padding=True
   ‚îÇ   )
   ‚îÇ
   ‚îî‚îÄ> –°–æ–∑–¥–∞—Ç—å labels
       ‚îî‚îÄ> –ú–∞—Å–∫–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º–ø—Ç, –æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç –¥–ª—è loss
```

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–¢–∏–ø–∏—á–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –ø–æ—Å–ª–µ fine-tuning:

```
–ú–ï–¢–†–ò–ö–ê         BASE MODEL    AFTER TRAINING    IMPROVEMENT
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
WER              24.5%           18.7%            -23.7%
CER              12.3%            8.9%            -27.6%

Training time: ~30 minutes (60 steps, batch_size=2)
```

### Model Formats

**1. Vision Model Structure:**
```
vision_model/
‚îú‚îÄ‚îÄ config.json
‚îÇ   ‚îú‚îÄ‚îÄ vision_config (ViT parameters)
‚îÇ   ‚îî‚îÄ‚îÄ text_config (Language model parameters)
‚îú‚îÄ‚îÄ model.safetensors (–∏–ª–∏ sharded)
‚îú‚îÄ‚îÄ preprocessor_config.json (image processing)
‚îú‚îÄ‚îÄ processor_config.json
‚îî‚îÄ‚îÄ tokenizer files
```

**2. Merged Vision Model:**
- –û–±—ä–µ–¥–∏–Ω—è–µ—Ç LoRA –≤–µ—Å–∞ —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
- –í–∫–ª—é—á–∞–µ—Ç –∫–∞–∫ vision, —Ç–∞–∫ –∏ language –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
- –†–∞–∑–º–µ—Ä: ~14GB (16-bit), ~7GB (4-bit)

---

## –°–≤–æ–¥–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤

| –ü–∞–π–ø–ª–∞–π–Ω | –¢–∏–ø | –û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ | –ö–ª—é—á–µ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞ | –ú–æ–¥–µ–ª—å |
|----------|-----|-----------------|------------------|--------|
| Synthetic Data | –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö | –°–æ–∑–¥–∞–Ω–∏–µ QA –ø–∞—Ä –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ | Quality Rating (1-10) | Llama-3.1-8B-Instruct |
| AIME Evaluation | –û—Ü–µ–Ω–∫–∞ | –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ | Accuracy, Pass@k | Any LLM |
| Training (GSM8K/LIMO) | –û–±—É—á–µ–Ω–∏–µ | –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–µ | AIME Accuracy | Llama-3.2-3B-Instruct |
| Vision OCR | –û–±—É—á–µ–Ω–∏–µ + –û—Ü–µ–Ω–∫–∞ | –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ | WER, CER | Qwen2-VL-7B-Instruct |

### –û–±—â–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

#### 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π

–í—Å–µ –ø–∞–π–ø–ª–∞–π–Ω—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç –ø–æ—Ö–æ–∂—É—é —Å—Ö–µ–º—É –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏:

```
Load Model ‚îÄ‚îÄ> Configure ‚îÄ‚îÄ> Setup LoRA (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ‚îÄ‚îÄ> Training/Inference
```

**–û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `max_seq_length`: 2048-32768
- `gpu_memory_utilization`: 0.8-0.98
- `load_in_4bit`: True/False (–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–∞–¥–∞—á–∏)
- `fast_inference`: True (–¥–ª—è vLLM)

#### 2. –ü—Ä–æ–º–ø—Ç-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ (OpenAI format):

```json
{
  "messages": [
    {"role": "system", "content": "..."},
    {"role": "user", "content": "..."},
    {"role": "assistant", "content": "..."}
  ]
}
```

#### 3. Evaluation Pattern

–û–±—â–∞—è —Å—Ö–µ–º–∞ –æ—Ü–µ–Ω–∫–∏:

```
Load Dataset ‚îÄ‚îÄ> Format ‚îÄ‚îÄ> Generate ‚îÄ‚îÄ> Extract Answer ‚îÄ‚îÄ> Calculate Metrics ‚îÄ‚îÄ> Save Results
```

#### 4. LoRA Training Pattern

```
Base Model ‚îÄ‚îÄ> Apply LoRA ‚îÄ‚îÄ> Train ‚îÄ‚îÄ> Evaluate ‚îÄ‚îÄ> Save (adapters/merged)
```

**–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ LoRA –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- Language models: r=64, alpha=128
- Vision models: r=16, alpha=32
- lora_dropout: 0
- bias: "none"

### –í–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     PIPELINE INTERACTIONS                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Synthetic Data Pipeline
         ‚îÇ
         ‚îî‚îÄ‚îÄ> Generates training data
                    ‚îÇ
                    v
         Training Pipeline (GSM8K/LIMO)
                    ‚îÇ
                    ‚îî‚îÄ‚îÄ> Trained model
                              ‚îÇ
                              v
                    AIME Evaluation Pipeline
                              ‚îÇ
                              ‚îî‚îÄ‚îÄ> Performance metrics

Vision OCR Pipeline (–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π)
         ‚îÇ
         ‚îî‚îÄ‚îÄ> –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ multimodal –¥–∞–Ω–Ω—ã—Ö
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã

**1. Synthetic Data:**
- `synthetic_data_kit_config.yaml` - –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
- –°–æ–¥–µ—Ä–∂–∏—Ç paths, generation params, cleanup config

**2. Training:**
- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤—Å—Ç—Ä–æ–µ–Ω–∞ –≤ –∫–æ–¥
- SFTConfig / GRPOConfig –æ–±—ä–µ–∫—Ç—ã

**3. Evaluation:**
- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –∫–∞–∫ –∞—Ä–≥—É–º–µ–Ω—Ç—ã —Ñ—É–Ω–∫—Ü–∏–π
- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ JSON

### –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –ø–∞–π–ø–ª–∞–π–Ω–∞–º

**Synthetic Data:**
- Quality rating: 1-10 (threshold –æ–±—ã—á–Ω–æ 1.0+)
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ä

**AIME:**
- Accuracy: % –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
- Pass@k: % –∑–∞–¥–∞—á —Å >= 1 –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –∏–∑ k –ø–æ–ø—ã—Ç–æ–∫
- –¢–æ–∫–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

**Training:**
- AIME improvement: —Ä–∞–∑–Ω–∏—Ü–∞ –¥–æ/–ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è
- Format compliance: % –æ—Ç–≤–µ—Ç–æ–≤ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏

**Vision OCR:**
- WER: Word Error Rate (lower is better)
- CER: Character Error Rate (lower is better)

### –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏

| –ü–∞–π–ø–ª–∞–π–Ω | –¢–∏–ø–∏—á–Ω–æ–µ –≤—Ä–µ–º—è | –§–∞–∫—Ç–æ—Ä—ã |
|----------|----------------|---------|
| Synthetic Data | 1-5 –º–∏–Ω/–¥–æ–∫—É–º–µ–Ω—Ç | –†–∞–∑–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞, num_pairs |
| AIME Evaluation | 10-30 –º–∏–Ω | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á, n_sampling |
| Training (GRPO) | 1-4 —á–∞—Å–∞ | Dataset size, num_epochs |
| Vision OCR | 30-60 –º–∏–Ω | Training steps, batch_size |

### –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ø–∞–º—è—Ç–∏

| –ü–∞–π–ø–ª–∞–π–Ω | GPU Memory | –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ |
|----------|------------|-------------|
| Synthetic Data | 16-24 GB | vLLM, 4-bit quantization |
| AIME Evaluation | 16-40 GB | –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –º–æ–¥–µ–ª–∏ |
| Training (LoRA) | 24-40 GB | Gradient checkpointing, small batch |
| Vision OCR | 40-80 GB | Vision —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏ |

### –§–æ—Ä–º–∞—Ç—ã –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

**JSON (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏):**
```json
{
  "results": {
    "accuracy": 0.45,
    "metric": "value"
  },
  "records": {
    "task_id": {
      "input": "...",
      "output": "...",
      "correct": true
    }
  }
}
```

**JSONL (–æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ):**
```jsonl
{"messages": [...], "answer": "..."}
{"messages": [...], "answer": "..."}
```

**YAML (–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏):**
```yaml
paths:
  input: "data/input"
  output: "data/output"
generation:
  temperature: 0.7
  max_tokens: 512
```

### –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏

1. **Synthetic Data Generation:**
   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ overlap –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
   - –ü—Ä–∏–º–µ–Ω—è–π—Ç–µ cleanup —Å –ø–æ—Ä–æ–≥–æ–º –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–∞
   - Batch —Ä–∞–∑–º–µ—Ä 4 –¥–ª—è —Ä–µ–π—Ç–∏–Ω–≥–∞ –æ–ø—Ç–∏–º–∞–ª–µ–Ω

2. **AIME Evaluation:**
   - n_sampling=8 –¥–ª—è –Ω–∞–¥–µ–∂–Ω—ã—Ö Pass@k –º–µ—Ç—Ä–∏–∫
   - temperature=0.3 –¥–ª—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á
   - Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

3. **Training:**
   - –ù–∞—á–∏–Ω–∞–π—Ç–µ —Å SFT, –∑–∞—Ç–µ–º GRPO
   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ GRPO –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∞
   - –í–∞–ª–∏–¥–∏—Ä—É–π—Ç–µ –Ω–∞ AIME –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏

4. **Vision OCR:**
   - –ë–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞
   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à–∏–π LoRA rank (16 vs 64)
   - Gradient checkpointing –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏

---

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** 2025-11-13
**–í—Å–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤:** 4
**–í–µ—Ä—Å–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:** 1.0

